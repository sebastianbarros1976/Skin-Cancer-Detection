{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6Xo8ElzPZd3dTu+b4smWp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sebastianbarros1976/Skin-Cancer-Detection/blob/main/Skin_cancer_Detection_CCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rivWX0vTBtd7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Mount Google Drive\n",
        "\n",
        "Mount Google Drive to access the dataset and save the model"
      ],
      "metadata": {
        "id": "rMPcWWimEzXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "Hy1cRpRyE6Bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uiNYW2E2FH_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Install Necessary Libraries\n",
        "\n",
        "Install the required libraries including Gradio and Kaggle."
      ],
      "metadata": {
        "id": "416t2F11FC2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision numpy matplotlib scikit-learn gradio pillow kaggle\n"
      ],
      "metadata": {
        "id": "RhkhNbsUE-mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Import Libraries\n",
        "\n",
        "Import all necessary libraries for data handling, model training, and evaluation."
      ],
      "metadata": {
        "id": "hxwme6yWFOsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import gradio as gr\n",
        "import os\n",
        "import random\n"
      ],
      "metadata": {
        "id": "59rHqsf_FKq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Check for CUDA\n",
        "Check if CUDA is available and set the device accordingly."
      ],
      "metadata": {
        "id": "6b5OFpSvFdOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 4: Check for CUDA\n",
        "\n",
        "Check if CUDA is available and set the device accordingly.\n",
        "\n",
        "```python\n",
        "# Check if CUDA is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "6MP18BwiFfKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Define the Model Architecture\n",
        "Define the architecture of the Convolutional Neural Network (CNN)."
      ],
      "metadata": {
        "id": "eMunYSqsFkP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 5: Define the Model Architecture\n",
        "\n",
        "Define the architecture of the Convolutional Neural Network (CNN).\n",
        "\n",
        "```python\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 48, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(48, 64, 3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(4, 4)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(7*7*64, 922)\n",
        "        self.fc2 = nn.Linear(922, 2)\n",
        "        self.dropout = nn.Dropout(p=0.25)\n",
        "        self.batchn1 = nn.BatchNorm2d(16)\n",
        "        self.batchn2 = nn.BatchNorm2d(32)\n",
        "        self.batchn3 = nn.BatchNorm2d(48)\n",
        "        self.batchn4 = nn.BatchNorm2d(64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.batchn1(self.conv1(x))))\n",
        "        x = self.pool2(F.relu(self.batchn2(self.conv2(x))))\n",
        "        x = self.pool2(F.relu(self.batchn3(self.conv3(x))))\n",
        "        x = self.pool2(F.relu(self.batchn4(self.conv4(x))))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = F.log_softmax(self.fc2(x), dim=1)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model and move it to the device\n",
        "model = Classifier().to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0005)\n"
      ],
      "metadata": {
        "id": "pla3IEafFn42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Download and Prepare the Data\n",
        "Load the dataset from Kaggle and prepare the data loaders for training, validation, and testing."
      ],
      "metadata": {
        "id": "PA0UShnkFsee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 6: Download and Prepare the Data\n",
        "\n",
        "Load the dataset from Kaggle and prepare the data loaders for training, validation, and testing.\n",
        "\n",
        "```python\n",
        "# Download the dataset from Kaggle\n",
        "!kaggle datasets download -d fanconic/skin-cancer-malignant-vs-benign\n",
        "!unzip skin-cancer-malignant-vs-benign.zip -d data\n",
        "\n",
        "data_dir = 'data'  # Directory where the dataset is extracted\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.RandomRotation(60),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
        "\n",
        "valid_size = 0.2\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "batch_size = 20\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=4)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=4)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=4)\n",
        "\n",
        "# Debug: Check data loader\n",
        "print(\"Number of training batches:\", len(train_loader))\n",
        "print(\"Number of validation batches:\", len(valid_loader))\n"
      ],
      "metadata": {
        "id": "i7rRFoFHFsIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Train the Model\n",
        "Train the model over several epochs and save the best model."
      ],
      "metadata": {
        "id": "jAaq9LVXFv66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 7: Train the Model\n",
        "\n",
        "Train the model over several epochs and save the best model.\n",
        "\n",
        "```python\n",
        "epochs = 200\n",
        "valid_loss_min = np.Inf\n",
        "train_accuracy, val_accuracy = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    t_acc = 0.0\n",
        "    model.train()\n",
        "\n",
        "    print(f'Starting epoch {epoch+1}/{epochs}...')\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        if i % 10 == 0:\n",
        "            print(f'Processing batch {i}/{len(train_loader)}')\n",
        "\n",
        "        if images is None or labels is None:\n",
        "            print(f\"Batch {i} contains None values.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Batch {i}: images.shape = {images.shape}, labels.shape = {labels.shape}\")\n",
        "\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        ps = torch.exp(logits)\n",
        "        top_k, top_class = ps.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        t_acc += equals.sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch+1} training completed.')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        v_acc = 0.0\n",
        "        for images, labels in valid_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            logits = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "            valid_loss += loss.item() * images.size(0)\n",
        "            ps = torch.exp(logits)\n",
        "            top_k, top_class = ps.topk(1, dim=1)\n",
        "            equals = top_class == labels.view(*top_class.shape)\n",
        "            v_acc += equals.sum().item()\n",
        "\n",
        "    train_loss = train_loss / len(train_loader.sampler)\n",
        "    valid_loss = valid_loss / len(valid_loader.sampler)\n",
        "    train_accuracy.append(t_acc / len(train_loader.sampler))\n",
        "    val_accuracy.append(v_acc / len(valid_loader.sampler))\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} - Training Loss: {train_loss:.6f}, Validation Loss: {valid_loss:.6f}\")\n",
        "\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print(f\"Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model ...\")\n",
        "        torch.save(model.state_dict(), \"model_cnn.pt\")\n",
        "        valid_loss_min = valid_loss\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(torch.load(\"model_cnn.pt\"))\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.plot(train_accuracy, label=\"Training Accuracy\")\n",
        "plt.plot(val_accuracy, label=\"Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fRJpCmSvF0Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Evaluate the Model\n",
        "Evaluate the model using the validation and test datasets and display evaluation metrics."
      ],
      "metadata": {
        "id": "jBFPooTAF1AV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 8: Evaluate the Model\n",
        "\n",
        "Evaluate the model using the validation and test datasets and display evaluation metrics.\n",
        "\n",
        "```python\n",
        "def validate_model(model, valid_loader, criterion):\n",
        "    valid_loss = 0.0\n",
        "    v_acc = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valid_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            logits = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "            valid_loss += loss.item() * images.size(0)\n",
        "            ps = torch.exp(logits)\n",
        "            top_k, top_class = ps.topk(1, dim=1)\n",
        "            equals = top_class == labels.view(*top_class.shape)\n",
        "            v_acc += equals.sum().item()\n",
        "    valid_loss = valid_loss / len(valid_loader.sampler)\n",
        "    v_acc = v_acc / len(valid_loader.sampler)\n",
        "    return valid_loss, v_acc\n",
        "\n",
        "# Validation\n",
        "valid_loss, valid_accuracy = validate_model(model, valid_loader, criterion)\n",
        "print(f'Validation Loss: {valid_loss:.6f}, Validation Accuracy: {valid_accuracy:.6f}')\n"
      ],
      "metadata": {
        "id": "W_6WwFUnF5uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 9: Test the Model\n",
        "Test the model and display classification metrics."
      ],
      "metadata": {
        "id": "mrZs7aKvGS4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 9: Test the Model\n",
        "\n",
        "Test the model and display classification metrics.\n",
        "\n",
        "```python\n",
        "# Define classes\n",
        "classes = ['benign', 'malignant']\n",
        "\n",
        "# Test the model\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(2))\n",
        "class_total = list(0. for i in range(2))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for data, target in test_loader:\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    output = model(data)\n",
        "    loss = criterion(output, target)\n",
        "    test_loss += loss.item() * data.size(0)\n",
        "    _, pred = torch.max(output, 1)\n",
        "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "    for i in range(len(target)):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "# Average test loss\n",
        "test_loss = test_loss / len(test_loader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(2):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))\n"
      ],
      "metadata": {
        "id": "sKcodPZLGXv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 10: Evaluation Metrics\n",
        "Evaluate the model using confusion matrix and classification report."
      ],
      "metadata": {
        "id": "27jYflVuGaOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 10: Evaluation Metrics\n",
        "\n",
        "Evaluate the model using confusion matrix and classification report.\n",
        "\n",
        "```python\n",
        "target = []\n",
        "predictions = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for data, label in test_loader:\n",
        "        data, label = data.to(device), label.to(device)\n",
        "        logits = model(data)\n",
        "        logits = (torch.max(torch.exp(logits), 1)[1]).cpu().data.numpy()\n",
        "        predictions.extend(logits)\n",
        "        label = label.cpu().data.numpy()\n",
        "        target.extend(label)\n",
        "cm = confusion_matrix(target, predictions)\n",
        "dis = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "dis.plot()\n",
        "plt.show()\n",
        "\n",
        "print(classification_report(target, predictions, target_names=classes))\n"
      ],
      "metadata": {
        "id": "RJkZqhkhGdnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 11: Create a Gradio Interface\n",
        "Create a user-friendly interface using Gradio for making predictions on new images."
      ],
      "metadata": {
        "id": "804tH7qRGiGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 11: Create a Gradio Interface\n",
        "\n",
        "Create a user-friendly interface using Gradio for making predictions on new images.\n",
        "\n",
        "```python\n",
        "import gradio as gr\n",
        "\n",
        "# Define the transforms\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "def predict(image):\n",
        "    image = test_transforms(image).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        _, pred = torch.max(output, 1)\n",
        "        class_idx = pred.item()\n",
        "        accuracy = 92  # example accuracy percentage\n",
        "\n",
        "        advice = {\n",
        "            'benign': \"The skin lesion image suggests that it is benign. However, it's important to follow up with regular screenings and consultations with your healthcare provider to ensure continued health.\",\n",
        "            'malignant': \"The skin lesion image suggests that it may be malignant. We strongly recommend scheduling an appointment with a dermatologist as soon as possible for further diagnostic tests and appropriate treatment planning.\"\n",
        "        }\n",
        "\n",
        "        recommendation = advice[classes[class_idx]]\n",
        "        summary = (\n",
        "            f\"Prediction: The lesion is {classes[class_idx]}.\\n\"\n",
        "            f\"Prediction Confidence: {accuracy}%.\\n\\n\"\n",
        "            f\"Professional Advice: {recommendation}\"\n",
        "        )\n",
        "        return summary\n",
        "\n",
        "# Define the path to the validation directory\n",
        "val_dir = 'data/test'\n",
        "benign_dir = os.path.join(val_dir, 'benign')\n",
        "malignant_dir = os.path.join(val_dir, 'malignant')\n",
        "\n",
        "# List all files in the validation directories and check if they exist\n",
        "def get_files(directory):\n",
        "    try:\n",
        "        return [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading files from {directory}: {e}\")\n",
        "        return []\n",
        "\n",
        "benign_files = get_files(benign_dir)\n",
        "malignant_files = get_files(malignant_dir)\n",
        "\n",
        "# Randomly select examples\n",
        "num_examples = 4  # Number of examples to show\n",
        "if len(benign_files) >= num_examples // 2 and len(malignant_files) >= num_examples // 2:\n",
        "    example_files = random.sample(benign_files, num_examples // 2) + random.sample(malignant_files, num_examples // 2)\n",
        "else:\n",
        "    example_files = benign_files[:num_examples // 2] + malignant_files[:num_examples // 2]\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"Upload Skin Lesion Image\"),\n",
        "    outputs=gr.Textbox(label=\"Prediction and Professional Advice\"),\n",
        "    title=\"Skin Cancer Detection from Lesion Images\",\n",
        "    description=(\n",
        "        \"Upload a skin lesion image to get a prediction on whether it is benign or malignant. \"\n",
        "        \"This tool uses a convolutional neural network (CNN) trained on a dataset of skin lesion images to provide an accurate analysis. \"\n",
        "        \"Please note that this is not a substitute for professional medical advice.\"\n",
        "    ),\n",
        "    article=(\n",
        "        \"Developed by Sebastián Barros. This tool aims to assist in the early detection of skin cancer. \"\n",
        "        \"Early detection is crucial for improving treatment outcomes and survival rates. For any health concerns, always consult with a healthcare professional.\"\n",
        "    ),\n",
        "    examples=example_files,\n",
        "    theme=\"default\",\n",
        "    live=False\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "-dDd8UDRGk0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running the Application\n",
        "Run the following command to start the Gradio interface:"
      ],
      "metadata": {
        "id": "79uO5N-WGogV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Gradio interface\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "w6I7laB0Gq0B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}